{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adbc96ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sklearn\n",
    "from sklearn.base import is_classifier, is_regressor\n",
    "\n",
    "\n",
    "class Metrics:\n",
    "    \"\"\"\n",
    "    A class used to determinte appropriate metrics.\n",
    "    Used for standardization across model types.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    infer_metrics(model)\n",
    "        Returns metrics based on whether a model is a classifier or regressor.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def infer_metrics(model):\n",
    "        if is_classifier(model):\n",
    "            return {\n",
    "                'F1': sklearn.metrics.f1_score,\n",
    "                'Accuracy': sklearn.metrics.accuracy_score\n",
    "            }\n",
    "        elif is_regressor(model):\n",
    "            return {\n",
    "                'MSE': sklearn.metrics.mean_squared_error,\n",
    "                'MAE': sklearn.metrics.mean_absolute_error,\n",
    "            }\n",
    "        else:\n",
    "            logging.warning(\"Model is neither a regressor or classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042007c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import importlib\n",
    "import logging\n",
    "import sklearn\n",
    "from typing import List\n",
    "import mlflow\n",
    "\n",
    "class Model:\n",
    "    \"\"\"\n",
    "    A class used to represent an ML model and relevant use cases.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    model : sklearn.base.BaseEstimator\n",
    "        sklearn model to be used for predictions\n",
    "    metrics : List[dict]\n",
    "        list of metrics to be used during evaluation\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        import_module: str,\n",
    "        model_params: dict = {}\n",
    "    ):\n",
    "        self.model = self.get_model(model_name, import_module, model_params)\n",
    "        self.metrics = Metrics.infer_metrics(self.model)\n",
    "\n",
    "    def get_model(self,\n",
    "                  model_name: str, import_module: str, model_params: dict\n",
    "                  ) -> sklearn.base.BaseEstimator:\n",
    "        \"\"\"\n",
    "        Returns instantiated sklearn model defined by parameters.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_name : str\n",
    "            Name of sklearn model e.g. \"RandomForestClassifier\"\n",
    "\n",
    "        import_module : str\n",
    "            Name of import module of sklearn base estimator e.g. \"sklearn.ensemble\"\n",
    "\n",
    "        model_params : dict\n",
    "           Dictionary defining sklearn model parameters \n",
    "\n",
    "        \"\"\"\n",
    "        model_class = getattr(\n",
    "            importlib.import_module(import_module), model_name)\n",
    "        model = model_class(**model_params)\n",
    "        return model\n",
    "\n",
    "    def predict(self, X: DataFrame):\n",
    "        \"\"\"\n",
    "        Returns array-like of predicted values given features.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : DataFrame\n",
    "            DataFrame of input data to be used for predictions\n",
    "\n",
    "        \"\"\"\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def evaluate(self, true, pred) -> List[dict]:\n",
    "        \"\"\"\n",
    "        Creates evaluation metrics comparing predicted and actual values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        true : array-like\n",
    "            actual values to compare predictions against\n",
    "\n",
    "        pred : array-like\n",
    "            predictions from model\n",
    "\n",
    "        \"\"\"\n",
    "        values = []\n",
    "        for metric in self.metrics:\n",
    "            values.append({\n",
    "                'metric_name': metric,\n",
    "                'metric_value': self.metrics[metric](true, pred)\n",
    "            })\n",
    "        logging.info(values)\n",
    "        return values\n",
    "\n",
    "    def log_metrics(self, metrics: List[dict]):\n",
    "        \"\"\"\n",
    "        Uses the log() function to iterate through metrics returned by evaluate()\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        metrics : List[dict]\n",
    "            metrics with metric name and metric value e.g. {'RMSE': 0.9}\n",
    "\n",
    "        \"\"\"\n",
    "        for metric in metrics:\n",
    "            self.log(metric['metric_name'], metric['metric_value'])\n",
    "\n",
    "    def log(self, metric_name: str, metric_value: float):\n",
    "        \"\"\"\n",
    "        Uses MLflow to log metric.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        metric_name : str\n",
    "            name of metric\n",
    "\n",
    "        metric_value : number\n",
    "            metric value\n",
    "\n",
    "        \"\"\"\n",
    "        mlflow.log_metric(metric_name, metric_value)\n",
    "\n",
    "    def mlflow_log_model(self):\n",
    "        \"\"\"\n",
    "        Logs model within ML run folder in /artifacts created by MLflow\n",
    "\n",
    "        \"\"\"\n",
    "        mlflow.sklearn.log_model(self.model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03493c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class PreProcessor:\n",
    "    def __init__(self,\n",
    "                 numeric_features: List[str] = [],\n",
    "                 categorical_features: List[str] = []\n",
    "                 ):\n",
    "        self.numeric_features = numeric_features\n",
    "        self.categorical_features = categorical_features\n",
    "\n",
    "    def x_y_split(self, df: pd.DataFrame, label: str):\n",
    "        df_X = df.drop(label, axis=1)\n",
    "        df_y = df[label]\n",
    "        return df_X, df_y\n",
    "\n",
    "    def train_test_split(self, X: pd.DataFrame, y, split_ratio: float = 0.8):\n",
    "        assert 0 < split_ratio < 1.0, \"split_ratio must be a value between 0 and 1\"\n",
    "        return train_test_split(X, y, train_size=split_ratio)\n",
    "\n",
    "    def create_transformer(self, numerical_imputer: str = 'median') -> ColumnTransformer:\n",
    "        transformers = []\n",
    "        if self.numeric_features:\n",
    "            numeric_transformer = Pipeline(\n",
    "                steps=[(\"imputer\", SimpleImputer(strategy=numerical_imputer)),\n",
    "                       (\"scaler\", StandardScaler())]\n",
    "            )\n",
    "            transformers.append(\n",
    "                (\"num\", numeric_transformer, self.numeric_features))\n",
    "        if self.categorical_features:\n",
    "            categorical_transformer = OneHotEncoder(\n",
    "                handle_unknown=\"infrequent_if_exist\")\n",
    "            transformers.append(\n",
    "                (\"cat\", categorical_transformer, self.categorical_features))\n",
    "\n",
    "        transformer = ColumnTransformer(\n",
    "            transformers=transformers\n",
    "        )\n",
    "\n",
    "        return transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05157bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "model_save_path = 'saved_models/RandomForestClassifier'\n",
    "train_data_path = 'data/train.csv'\n",
    "model_name = 'RandomForestClassifier'\n",
    "import_module = 'sklearn.ensemble'\n",
    "model_params = {}\n",
    "\n",
    "def train():\n",
    "    data = pd.read_csv(train_data_path)\n",
    "\n",
    "    model = Model(\n",
    "        model_name=model_name,\n",
    "        import_module=import_module,\n",
    "        model_params=model_params\n",
    "    )\n",
    "\n",
    "    preprocessor = PreProcessor(\n",
    "        categorical_features=[2, 5, 6],\n",
    "        numeric_features=[0, 1, 3, 4]\n",
    "    )\n",
    "\n",
    "    X, y = preprocessor.x_y_split(data, 'y')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = preprocessor.train_test_split(X, y)\n",
    "\n",
    "    transformer = preprocessor.create_transformer()\n",
    "\n",
    "    clf = Pipeline(\n",
    "        steps=[(\"preprocessor\", transformer),\n",
    "               (\"classifier\", model.model)]\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    metrics = model.evaluate(y_test, pred)\n",
    "\n",
    "    model.log_metrics(metrics)\n",
    "\n",
    "    model.save_model()\n",
    "\n",
    "    joblib.dump(clf, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50e97357",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'save_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(y_test, pred)\n\u001b[1;32m     41\u001b[0m model\u001b[38;5;241m.\u001b[39mlog_metrics(metrics)\n\u001b[0;32m---> 43\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m()\n\u001b[1;32m     45\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(clf, model_save_path)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'save_model'"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "85ae21fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(x_test.iloc[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "15fbf3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.79584, 21.592293, 'Thu', -1.139312, 122.274831, 'California', 'ford']]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.iloc[0:1].to_numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d5ede3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(x_test.iloc[0:1].to_numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d3f1610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0105c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load('saved_models/RandomForestClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "994823eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[2.79584, 21.592293, 'Thu', -1.139312, 122.274831, 'California', 'ford']]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b8d269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
